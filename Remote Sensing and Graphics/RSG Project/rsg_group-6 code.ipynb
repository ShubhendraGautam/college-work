{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import gdown\n",
        "url = \"https://drive.google.com/uc?id=1kR4yNafYdhuGSo4kPI1HwApmluY3L1Oq\"\n",
        "\n",
        "output_zip_path = \"/content/KPCAMNet_dataset.zip\"\n",
        "\n",
        "# Download the file using gdown\n",
        "gdown.download(url, output_zip_path, quiet=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        },
        "id": "m8nYQS3V4UL6",
        "outputId": "7fffd94f-02d9-425a-f6ff-5dc624278c74"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1kR4yNafYdhuGSo4kPI1HwApmluY3L1Oq\n",
            "From (redirected): https://drive.google.com/uc?id=1kR4yNafYdhuGSo4kPI1HwApmluY3L1Oq&confirm=t&uuid=d7c22aa4-f8c4-45e1-84da-cbe8a356ab30\n",
            "To: /content/KPCAMNet_dataset.zip\n",
            "100%|██████████| 28.0M/28.0M [00:00<00:00, 72.6MB/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/KPCAMNet_dataset.zip'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/KPCAMNet_dataset.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5DYZmCkx4wxt",
        "outputId": "e21beb97-4b63-471a-871f-9a78a4d53315"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/KPCAMNet_dataset.zip\n",
            "   creating: KPCAMNet_dataset/\n",
            "   creating: KPCAMNet_dataset/HY/\n",
            "   creating: KPCAMNet_dataset/HY/labels/\n",
            "  inflating: KPCAMNet_dataset/HY/labels/change.bmp  \n",
            "  inflating: KPCAMNet_dataset/HY/labels/GT.bmp  \n",
            "  inflating: KPCAMNet_dataset/HY/labels/multi-change.bmp  \n",
            "  inflating: KPCAMNet_dataset/HY/labels/unchanged.bmp  \n",
            "   creating: KPCAMNet_dataset/HY/raw data/\n",
            "  inflating: KPCAMNet_dataset/HY/raw data/T1  \n",
            "  inflating: KPCAMNet_dataset/HY/raw data/T1.hdr  \n",
            "  inflating: KPCAMNet_dataset/HY/raw data/T2  \n",
            "  inflating: KPCAMNet_dataset/HY/raw data/T2.hdr  \n",
            "   creating: KPCAMNet_dataset/HY/visualized img/\n",
            " extracting: KPCAMNet_dataset/HY/visualized img/T1.png  \n",
            " extracting: KPCAMNet_dataset/HY/visualized img/T2.png  \n",
            "   creating: KPCAMNet_dataset/QU/\n",
            "   creating: KPCAMNet_dataset/QU/labels/\n",
            "  inflating: KPCAMNet_dataset/QU/labels/change.bmp  \n",
            "  inflating: KPCAMNet_dataset/QU/labels/GT.png  \n",
            "  inflating: KPCAMNet_dataset/QU/labels/GT_multi.bmp  \n",
            "  inflating: KPCAMNet_dataset/QU/labels/multi-change.bmp  \n",
            "  inflating: KPCAMNet_dataset/QU/labels/unchanged.bmp  \n",
            "   creating: KPCAMNet_dataset/QU/raw data/\n",
            "  inflating: KPCAMNet_dataset/QU/raw data/T1  \n",
            "  inflating: KPCAMNet_dataset/QU/raw data/T1.hdr  \n",
            "  inflating: KPCAMNet_dataset/QU/raw data/T2  \n",
            "  inflating: KPCAMNet_dataset/QU/raw data/T2.hdr  \n",
            "   creating: KPCAMNet_dataset/QU/visualized img/\n",
            " extracting: KPCAMNet_dataset/QU/visualized img/T1.png  \n",
            " extracting: KPCAMNet_dataset/QU/visualized img/T2.png  \n",
            "  inflating: KPCAMNet_dataset/README.md  \n",
            "   creating: KPCAMNet_dataset/WH/\n",
            "   creating: KPCAMNet_dataset/WH/labels/\n",
            "  inflating: KPCAMNet_dataset/WH/labels/change.bmp  \n",
            "  inflating: KPCAMNet_dataset/WH/labels/GT.bmp  \n",
            "  inflating: KPCAMNet_dataset/WH/labels/unchanged.bmp  \n",
            "   creating: KPCAMNet_dataset/WH/raw data/\n",
            "  inflating: KPCAMNet_dataset/WH/raw data/T1  \n",
            "  inflating: KPCAMNet_dataset/WH/raw data/T1.hdr  \n",
            "  inflating: KPCAMNet_dataset/WH/raw data/T2  \n",
            "  inflating: KPCAMNet_dataset/WH/raw data/T2.hdr  \n",
            "   creating: KPCAMNet_dataset/WH/visualized img/\n",
            " extracting: KPCAMNet_dataset/WH/visualized img/T1.png  \n",
            " extracting: KPCAMNet_dataset/WH/visualized img/T2.png  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from scipy.linalg import eig\n",
        "from scipy.stats import chi2\n",
        "from sklearn.cluster import KMeans\n",
        "\n",
        "\n",
        "def get_binary_change_map(data, method='k_means'):\n",
        "    \"\"\"\n",
        "    get binary change map\n",
        "    :param data:\n",
        "    :param method: cluster method\n",
        "    :return: binary change map\n",
        "    \"\"\"\n",
        "    if method == 'k_means':\n",
        "        cluster_center = KMeans(n_clusters=2, max_iter=1500).fit(data.T).cluster_centers_.T  # shape: (1, 2)\n",
        "        # cluster_center = k_means_cluster(weight, cluster_num=2)\n",
        "        print('k-means cluster is done, the cluster center is ', cluster_center)\n",
        "        dis_1 = np.linalg.norm(data - cluster_center[0, 0], axis=0, keepdims=True)\n",
        "        dis_2 = np.linalg.norm(data - cluster_center[0, 1], axis=0, keepdims=True)\n",
        "\n",
        "        bcm = np.copy(data)  # binary change map\n",
        "        if cluster_center[0, 0] > cluster_center[0, 1]:\n",
        "            bcm[dis_1 > dis_2] = 0\n",
        "            bcm[dis_1 <= dis_2] = 255\n",
        "        else:\n",
        "            bcm[dis_1 > dis_2] = 255\n",
        "            bcm[dis_1 <= dis_2] = 0\n",
        "    elif method == 'otsu':\n",
        "        bcm, threshold = otsu(data, num=200)\n",
        "        print('otsu is done, the threshold is ', threshold)\n",
        "\n",
        "    return bcm\n",
        "\n",
        "\n",
        "def otsu(data, num=400):\n",
        "    \"\"\"\n",
        "    generate binary change map based on otsu\n",
        "    :param data: cluster data\n",
        "    :param num: intensity number\n",
        "    :return:\n",
        "        binary change map\n",
        "        selected threshold\n",
        "    \"\"\"\n",
        "    max_value = np.max(data)\n",
        "    min_value = np.min(data)\n",
        "\n",
        "    total_num = data.shape[1]\n",
        "    step_value = (max_value - min_value) / num\n",
        "    value = min_value\n",
        "    best_threshold = min_value\n",
        "    best_inter_class_var = 0\n",
        "    while value <= max_value:\n",
        "        data_1 = data[data <= value]\n",
        "        data_2 = data[data > value]\n",
        "        w1 = data_1.shape[0] / total_num\n",
        "        w2 = data_2.shape[0] / total_num\n",
        "\n",
        "        mean_1 = data_1.mean()\n",
        "        mean_2 = data_2.mean()\n",
        "\n",
        "        inter_class_var = w1 * w2 * np.power((mean_1 - mean_2), 2)\n",
        "        if best_inter_class_var < inter_class_var:\n",
        "            best_inter_class_var = inter_class_var\n",
        "            best_threshold = value\n",
        "        value += step_value\n",
        "\n",
        "    bwp = np.zeros(data.shape)\n",
        "    bwp[data <= best_threshold] = 0\n",
        "    bwp[data > best_threshold] = 255\n",
        "\n",
        "    return bwp, best_threshold"
      ],
      "metadata": {
        "id": "iJscbv9C3GtN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import imageio\n",
        "\n",
        "import numpy as np\n",
        "from sklearn.metrics import roc_curve\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import cohen_kappa_score\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "\n",
        "def assess_accuracy(gt_changed, gt_unchanged, changed_map, multi_class=False):\n",
        "    \"\"\"\n",
        "    assess accuracy of changed map based on ground truth\n",
        "    :param gt_changed: changed ground truth\n",
        "    :param gt_unchanged: unchanged ground truth\n",
        "    :param changed_map: changed map\n",
        "    :return: confusion matrix and overall accuracy\n",
        "    \"\"\"\n",
        "    cm = []\n",
        "    gt = []\n",
        "\n",
        "    if multi_class:\n",
        "        height, width, channel = gt_changed.shape\n",
        "        for i in range(0, height):\n",
        "            for j in range(0, width):\n",
        "                if (changed_map[i, j] == np.array([255, 255, 0])).all():\n",
        "                    cm.append('soil')\n",
        "                # elif (changed_map[i, j] == np.array([0, 0, 255])).all():\n",
        "                #     cm.append('water')\n",
        "                elif (changed_map[i, j] == np.array([255, 0, 0])).all():\n",
        "                    cm.append('city')\n",
        "                else:\n",
        "                    cm.append('unchanged')\n",
        "                if (gt_changed[i, j] == np.array([255, 255, 0])).all():\n",
        "                    gt.append('soil')\n",
        "                elif (gt_changed[i, j] == np.array([255, 0, 0])).all():\n",
        "                    gt.append('city')\n",
        "                # elif (gt_changed[i, j] == np.array([0, 0, 255])).all():\n",
        "                #     gt.append('water')\n",
        "                elif (gt_unchanged[i, j] == np.array([255, 255, 255])).all():\n",
        "                    gt.append('unchanged')\n",
        "                else:\n",
        "                    gt.append('undefined')\n",
        "        conf_mat = confusion_matrix(y_true=gt, y_pred=cm,\n",
        "                                    labels=['soil', 'city', 'unchanged'])\n",
        "        kappa_co = cohen_kappa_score(y1=gt, y2=cm,\n",
        "                                     labels=['soil', 'city', 'unchanged'])\n",
        "        aa = conf_mat.diagonal() / np.sum(conf_mat, axis=1)\n",
        "        oa = np.sum(conf_mat.diagonal()) / np.sum(conf_mat)\n",
        "\n",
        "        return conf_mat, oa, aa, kappa_co\n",
        "\n",
        "    else:\n",
        "        height, width = changed_map.shape\n",
        "        changed_map = np.reshape(changed_map, (-1,))\n",
        "        gt_changed = np.reshape(gt_changed, (-1,))\n",
        "        gt_unchanged = np.reshape(gt_unchanged, (-1,))\n",
        "\n",
        "        cm = np.ones((height * width,))\n",
        "        cm[changed_map == 255] = 2\n",
        "\n",
        "        gt = np.zeros((height * width,))\n",
        "        gt[gt_changed == 255] = 2\n",
        "        gt[gt_unchanged == 255] = 1\n",
        "\n",
        "\n",
        "        conf_mat = confusion_matrix(y_true=gt, y_pred=cm,\n",
        "                                    labels=[1, 2])  # ['soil', 'water', 'city', 'unchanged'])\n",
        "        kappa_co = cohen_kappa_score(y1=gt, y2=cm,\n",
        "                                     labels=[1, 2])  # ['soil', 'water', 'city', 'unchanged'])\n",
        "\n",
        "        oa = np.sum(conf_mat.diagonal()) / np.sum(conf_mat)\n",
        "\n",
        "        return conf_mat, oa, kappa_co\n",
        "\n",
        "\n",
        "\n",
        "# if __name__ == '__main__':\n",
        "#     # val_func()\n",
        "#     ground_truth_changed = imageio.imread('./Adata/GF_2_2/change.bmp')[:, :, 0]\n",
        "#     ground_truth_unchanged = imageio.imread('./Adata/GF_2_2/unchanged.bmp')  # [:, :, 1]\n",
        "\n",
        "#     cm_path = 'PCANet/compare/SAE_binary.bmp'\n",
        "#     changed_map = imageio.imread(cm_path)\n",
        "\n",
        "\n",
        "#     conf_mat, oa, kappa_co = assess_accuracy(ground_truth_changed, ground_truth_unchanged, changed_map,\n",
        "#                                                  multi_class=False)\n",
        "#     conf_mat_2 = conf_mat.copy()\n",
        "#     conf_mat_2[1, 1] = conf_mat[0, 0]\n",
        "#     conf_mat_2[0, 0] = conf_mat[1, 1]\n",
        "#     conf_mat_2[1, 0] = conf_mat[0, 1]\n",
        "#     conf_mat_2[0, 1] = conf_mat[1, 0]\n",
        "\n",
        "#     print(conf_mat)\n",
        "#     print(conf_mat_2[1, 0] + conf_mat_2[0, 1])\n",
        "#     print(oa)\n",
        "#     print(kappa_co)"
      ],
      "metadata": {
        "id": "-vTDhomo3XD3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "\n",
        "def norm_img(img, channel_first=True):\n",
        "    if channel_first:\n",
        "        channel, img_height, img_width = img.shape\n",
        "        img = np.reshape(img, (channel, img_height * img_width))  # (channel, height * width)\n",
        "        max_value = np.max(img, axis=1, keepdims=True)  # (channel, 1)\n",
        "        min_value = np.min(img, axis=1, keepdims=True)  # (channel, 1)\n",
        "        diff_value = max_value - min_value\n",
        "        nm_img = (img - min_value) / diff_value\n",
        "        nm_img = np.reshape(nm_img, (channel, img_height, img_width))\n",
        "    else:\n",
        "        img_height, img_width, channel = img.shape\n",
        "        img = np.reshape(img, (img_height * img_width, channel))  # (channel, height * width)\n",
        "        max_value = np.max(img, axis=0, keepdims=True)  # (channel, 1)\n",
        "        min_value = np.min(img, axis=0, keepdims=True)  # (channel, 1)\n",
        "        diff_value = max_value - min_value\n",
        "        nm_img = (img - min_value) / diff_value\n",
        "        nm_img = np.reshape(nm_img, (img_height, img_width, channel))\n",
        "    return nm_img\n",
        "\n",
        "\n",
        "def norm_img_2(img, channel_first=True):\n",
        "    if channel_first:\n",
        "        channel, img_height, img_width = img.shape\n",
        "        img = np.reshape(img, (channel, img_height * img_width))  # (channel, height * width)\n",
        "        max_value = np.max(img, axis=1, keepdims=True)  # (channel, 1)\n",
        "        min_value = np.min(img, axis=1, keepdims=True)  # (channel, 1)\n",
        "        diff_value = max_value - min_value\n",
        "        nm_img = 2 * ((img - min_value) / diff_value - 0.5)\n",
        "        nm_img = np.reshape(nm_img, (channel, img_height, img_width))\n",
        "    else:\n",
        "        img_height, img_width, channel = img.shape\n",
        "        img = np.reshape(img, (img_height * img_width, channel))  # (channel, height * width)\n",
        "        max_value = np.max(img, axis=0, keepdims=True)  # (channel, 1)\n",
        "        min_value = np.min(img, axis=0, keepdims=True)  # (channel, 1)\n",
        "        diff_value = max_value - min_value\n",
        "        nm_img = 2 * ((img - min_value) / diff_value - 0.5)\n",
        "        nm_img = np.reshape(nm_img, (img_height, img_width, channel))\n",
        "    return nm_img\n",
        "\n",
        "\n",
        "def stad_img(img, channel_first=True):\n",
        "    \"\"\"\n",
        "    normalization image\n",
        "    :param channel_first:\n",
        "    :param img: (C, H, W)\n",
        "    :return:\n",
        "        norm_img: (C, H, W)\n",
        "    \"\"\"\n",
        "    if channel_first:\n",
        "        channel, img_height, img_width = img.shape\n",
        "        img = np.reshape(img, (channel, img_height * img_width))  # (channel, height * width)\n",
        "        mean = np.mean(img, axis=1, keepdims=True)  # (channel, 1)\n",
        "        center = img - mean  # (channel, height * width)\n",
        "        var = np.sum(np.power(center, 2), axis=1, keepdims=True) / (img_height * img_width)  # (channel, 1)\n",
        "        std = np.sqrt(var)  # (channel, 1)\n",
        "        nm_img = center / std  # (channel, height * width)\n",
        "        nm_img = np.reshape(nm_img, (channel, img_height, img_width))\n",
        "    else:\n",
        "        img_height, img_width, channel = img.shape\n",
        "        img = np.reshape(img, (img_height * img_width, channel))  # (height * width, channel)\n",
        "        mean = np.mean(img, axis=0, keepdims=True)  # (1, channel)\n",
        "        center = img - mean  # (height * width, channel)\n",
        "        var = np.sum(np.power(center, 2), axis=0, keepdims=True) / (img_height * img_width)  # (1, channel)\n",
        "        std = np.sqrt(var)  # (channel, 1)\n",
        "        nm_img = center / std  # (channel, height * width)\n",
        "        nm_img = np.reshape(nm_img, (img_height, img_width, channel))\n",
        "    return nm_img\n",
        "\n",
        "\n",
        "def random_select_samples(img_X, img_Y, n_train, patch_sz):\n",
        "    '''\n",
        "        randomly selecting patches as training sample for KPCA convolution training\n",
        "    '''\n",
        "    height, width, channel = img_X.shape\n",
        "    edge = patch_sz // 2\n",
        "\n",
        "    img_X = np.pad(img_X, ((edge, edge), (edge, edge), (0, 0)), 'constant')\n",
        "    img_Y = np.pad(img_Y, ((edge, edge), (edge, edge), (0, 0)), 'constant')\n",
        "\n",
        "    patch_X = []\n",
        "    patch_Y = []\n",
        "\n",
        "    for i in range(0, height):\n",
        "        for j in range(0, width):\n",
        "            patch_X.append(img_X[i:i + patch_sz, j:j + patch_sz])\n",
        "            patch_Y.append(img_Y[i:i + patch_sz, j:j + patch_sz])\n",
        "    patch_X = np.array(patch_X, np.float32)\n",
        "    patch_Y = np.array(patch_Y, np.float32)\n",
        "\n",
        "    train_idx = np.arange(0, height * width)\n",
        "    np.random.seed()\n",
        "    np.random.shuffle(train_idx)\n",
        "    train_idx = train_idx[0:n_train]\n",
        "\n",
        "    train_X = patch_X[train_idx]\n",
        "    train_Y = patch_Y[train_idx]\n",
        "    return train_X, train_Y"
      ],
      "metadata": {
        "id": "yLm6XAu53nEm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.decomposition import KernelPCA\n",
        "\n",
        "\n",
        "class KernelPCANet(object):\n",
        "    def __init__(self, num_stages, patch_size, num_filters, gamma):\n",
        "        self.num_stages = num_stages\n",
        "        self.patch_size = patch_size\n",
        "        self.num_filters = num_filters\n",
        "\n",
        "        self.filters = []\n",
        "        self.gamma = gamma\n",
        "\n",
        "    def train_net(self, input_data, stage, is_mean_removal, kernel='rbf'):\n",
        "        return self.train_filters(input_data, stage, is_mean_removal, kernel)\n",
        "\n",
        "    def train_filters(self, input_data, stage, is_mean_removal, kernel):\n",
        "        input_shape = input_data.shape  # (B, m, n, c)\n",
        "        # generate overlap patch\n",
        "        print('-------patch generation-------')\n",
        "        overlap_patch = self._generate_over_patch(input_data)\n",
        "\n",
        "        overlap_patch = np.reshape(overlap_patch,  # (m * n, c * k1 * k2)\n",
        "                                   (-1, self.patch_size[0] * self.patch_size[1] * input_shape[-1]))\n",
        "\n",
        "        # overlap_patch = input_data\n",
        "        # mean removal\n",
        "        #  print('-------mean removal-------')\n",
        "        if is_mean_removal:\n",
        "            patch_mean = np.mean(overlap_patch, axis=1, keepdims=True)  # (m * n * c, 1)\n",
        "            mean_overlap_patch = overlap_patch - patch_mean  # (m * n * c, k1 * k2)\n",
        "        else:\n",
        "            mean_overlap_patch = overlap_patch\n",
        "\n",
        "        print('-------solve KPCA problem-------')\n",
        "        KPCA_trans = KernelPCA(n_components=self.num_filters[stage], kernel=kernel, degree=3, gamma=self.gamma[stage])\n",
        "        output = KPCA_trans.fit_transform(mean_overlap_patch)\n",
        "\n",
        "        self.filters.append(KPCA_trans)\n",
        "        return output\n",
        "\n",
        "    def infer_data(self, input_data, stage, is_mean_removal):\n",
        "        output_data = self.predict(input_data, stage, is_mean_removal)\n",
        "        return output_data\n",
        "\n",
        "    def predict(self, data, stage, is_mean_removal):\n",
        "        input_shape = data.shape\n",
        "        mar_ver = self.patch_size[0] // 2\n",
        "        mar_hor = self.patch_size[1] // 2\n",
        "        padding_img = np.zeros(\n",
        "            (input_shape[0],\n",
        "             input_shape[1] + 2 * mar_ver,\n",
        "             input_shape[2] + 2 * mar_hor,\n",
        "             input_shape[3]))\n",
        "        for i in range(input_shape[0]):  # (B, m, n, c) --> (B, m+filter_h, n+filter_w, c)\n",
        "            padding_img[i] = np.pad(data[i], ((mar_ver, mar_hor), (mar_ver, mar_hor), (0, 0)), 'constant')\n",
        "\n",
        "        # print('-------generate overlap patch-------')\n",
        "        overlap_patch = self._generate_over_patch(padding_img)\n",
        "\n",
        "        overlap_patch = np.reshape(overlap_patch,  # (m * n, c * k1 * k2)\n",
        "                                   (-1, self.patch_size[0] * self.patch_size[1] * input_shape[-1]))\n",
        "\n",
        "        # print('-------mean removal-------')\n",
        "        if is_mean_removal:\n",
        "            patch_mean = np.mean(overlap_patch, axis=1, keepdims=True)  # (m * n * c, 1)\n",
        "            mean_overlap_patch = overlap_patch - patch_mean  # (m * n * c, k1 * k2)\n",
        "        else:\n",
        "            mean_overlap_patch = overlap_patch\n",
        "\n",
        "        KPCA_trains = self.filters[stage]\n",
        "        trans_output = KPCA_trains.transform(mean_overlap_patch)\n",
        "\n",
        "        trans_output = np.reshape(trans_output,\n",
        "                                  (input_shape[0], input_shape[1], input_shape[2], self.num_filters[stage]))\n",
        "        return trans_output\n",
        "\n",
        "    def _generate_over_patch(self, data):\n",
        "        input_shape = data.shape\n",
        "        mar_ver = self.patch_size[0] // 2\n",
        "        mar_hor = self.patch_size[1] // 2\n",
        "\n",
        "        overlap_patch = []\n",
        "        for batch_id in range(input_shape[0]):\n",
        "            for i in range(mar_ver, input_shape[1] - mar_ver):\n",
        "                for j in range(mar_hor, input_shape[2] - mar_hor):\n",
        "                    # (B, k1, k2, c)\n",
        "                    patch = data[batch_id, (i - mar_ver):(i + mar_ver + 1), (j - mar_hor):(j + mar_hor + 1)]\n",
        "                    overlap_patch.append(patch)\n",
        "        overlap_patch = np.reshape(overlap_patch, (-1, self.patch_size[0], self.patch_size[1], input_shape[-1]))\n",
        "        return overlap_patch"
      ],
      "metadata": {
        "id": "vsuSB4-A3r9W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_BnAC_IDzUAk",
        "outputId": "6b1d82af-9be3-4d2a-9450-959a6b67b603"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sample number is 200\n",
            "-------patch generation-------\n",
            "-------solve KPCA problem-------\n",
            "-------patch generation-------\n",
            "-------solve KPCA problem-------\n",
            "-------patch generation-------\n",
            "-------solve KPCA problem-------\n",
            "-------Perform Binary Change Detection-------\n",
            "otsu is done, the threshold is  0.008253679594746105\n",
            "-------Perform Multi-class Change Detection-------\n",
            "-------Clustering algorithm is running\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import pickle\n",
        "import argparse\n",
        "\n",
        "from osgeo import gdal\n",
        "import numpy as np\n",
        "from sklearn.cluster import KMeans\n",
        "import sys\n",
        "# import KernelPCANet\n",
        "# import get_binary_change_map\n",
        "# import assess_accuracy\n",
        "# import stad_img, norm_img, random_select_samples\n",
        "import imageio\n",
        "\n",
        "DEFAULT_ARGS = {\n",
        "    'net_depth': 3,\n",
        "    'patch_size': 5,\n",
        "    'kernel_func': 'rbf',\n",
        "    'gamma_list': [5e-4, 5e-4, 5e-4],\n",
        "    'save_path': 'result',\n",
        "    'data_path': '/content/KPCAMNet_dataset/HY/raw data',\n",
        "    'epoch': 1,\n",
        "    'filter_num': [8, 8, 8],\n",
        "    'sample_num': 100,\n",
        "}\n",
        "\n",
        "# if len(FILTER_NUM) != NET_DEPTH:\n",
        "#     print('filter number doesn\\'t match network depth! Please check it')\n",
        "#     sys.exit(1)\n",
        "\n",
        "# if len(GAMMA) != len(FILTER_NUM):\n",
        "#     print('gamma number doesn\\' match filter number! Please check it')\n",
        "#     sys.exit(1)\n",
        "\n",
        "\n",
        "def load_data(data_path):\n",
        "    '''\n",
        "        load dataset, you should modify this function according to your own dataset\n",
        "    '''\n",
        "    data_set_X = gdal.Open(os.path.join(data_path, 'T1'))  # data set X\n",
        "    data_set_Y = gdal.Open(os.path.join(data_path, 'T2'))  # data set Y\n",
        "\n",
        "    img_width = data_set_X.RasterXSize  # image width\n",
        "    img_height = data_set_X.RasterYSize  # image height\n",
        "\n",
        "    img_X = data_set_X.ReadAsArray(0, 0, img_width, img_height)\n",
        "    img_Y = data_set_Y.ReadAsArray(0, 0, img_width, img_height)\n",
        "\n",
        "    img_X = stad_img(img_X, channel_first=True)  # (C, H, W)\n",
        "    img_Y = stad_img(img_Y, channel_first=True)\n",
        "    img_X = np.transpose(img_X, [1, 2, 0])  # (H, W, C)\n",
        "    img_Y = np.transpose(img_Y, [1, 2, 0])  # (H, W, C)\n",
        "    return img_X, img_Y\n",
        "\n",
        "\n",
        "def train_net(args):\n",
        "\n",
        "    FLAGS = DEFAULT_ARGS.copy()\n",
        "    FLAGS.update(args)\n",
        "\n",
        "    PATCH_SZ = FLAGS['patch_size']\n",
        "    NET_DEPTH = FLAGS['net_depth']\n",
        "    SAVE_PATH = FLAGS['save_path']\n",
        "    DATA_PATH = FLAGS['data_path']\n",
        "    KERNEL_FUNC = FLAGS['kernel_func']\n",
        "    GAMMA = FLAGS['gamma_list']\n",
        "    EPOCH = FLAGS['epoch']\n",
        "    FILTER_NUM = FLAGS['filter_num']\n",
        "    SAMPLE_NUM = FLAGS['sample_num']\n",
        "    img_X, img_Y = load_data(DATA_PATH)\n",
        "    height, width, channel = img_X.shape\n",
        "\n",
        "    print(f'sample number is {2 * SAMPLE_NUM}')\n",
        "\n",
        "    train_X, train_Y = random_select_samples(img_X, img_Y, n_train=SAMPLE_NUM, patch_sz=PATCH_SZ)\n",
        "    train_data = np.concatenate([train_X, train_Y], axis=0)\n",
        "\n",
        "    # limited by the memory size, we have to slide the dataset into 500*500 patch, you can define this according\n",
        "    # to your own dataset\n",
        "    step_1 = 500\n",
        "    step_2 = 500\n",
        "    before_img = np.reshape(img_X, (1, img_X.shape[0], img_X.shape[1], img_X.shape[2]))\n",
        "    after_img = np.reshape(img_Y, (1, img_Y.shape[0], img_Y.shape[1], img_Y.shape[2]))\n",
        "    pred_img = np.concatenate([before_img, after_img], axis=0)  # (2, H, W, C)\n",
        "    PCANet_model = KernelPCANet(num_stages=NET_DEPTH, patch_size=[PATCH_SZ, PATCH_SZ],\n",
        "                                num_filters=FILTER_NUM,\n",
        "                                gamma=GAMMA)\n",
        "    for s in range(NET_DEPTH):\n",
        "        trans_img = np.ones((2, height, width, FILTER_NUM[s]))\n",
        "        PCANet_model.train_net(train_data, stage=s, is_mean_removal=False, kernel=KERNEL_FUNC)\n",
        "\n",
        "        for i in range(0, height, step_1):\n",
        "            for j in range(0, width, step_2):\n",
        "                pred_data = pred_img[:, i:(i + step_1), j:(j + step_2), :]\n",
        "                net_output = PCANet_model.infer_data(pred_data, stage=s, is_mean_removal=False)\n",
        "                proj_before_img = net_output[0]\n",
        "                proj_after_img = net_output[1]\n",
        "                trans_img[0, i:(i + step_1), j:(j + step_2)] = proj_before_img\n",
        "                trans_img[1, i:(i + step_1), j:(j + step_2)] = proj_after_img\n",
        "\n",
        "        pred_img = np.copy(trans_img)  # feature images will be treated as input in the next stage\n",
        "\n",
        "        # select new training samples for the next KPCA convolutional layer\n",
        "        change_sample_X, change_sample_Y = random_select_samples(trans_img[0], trans_img[1],\n",
        "                                                                 n_train=SAMPLE_NUM,\n",
        "                                                                 patch_sz=PATCH_SZ)\n",
        "\n",
        "        train_data = np.concatenate([change_sample_X, change_sample_Y], axis=0)\n",
        "\n",
        "    #############################\n",
        "    # mapping data into a 2-D polar domain\n",
        "    #############################\n",
        "    diff_img = (trans_img[0] - trans_img[1])\n",
        "    rou = np.sqrt(np.sum(np.square(diff_img), axis=-1))\n",
        "    eig_value = PCANet_model.filters[-1].eigenvalues_\n",
        "    eig_value = np.reshape(eig_value, (1, 1, -1))\n",
        "    theta = np.arccos(1 / np.sqrt(FILTER_NUM[-1]) * (np.sum(eig_value * diff_img, -1) / np.sqrt(\n",
        "        np.sum(np.square(eig_value)) * np.sum(np.square(diff_img), axis=-1))))\n",
        "\n",
        "    ###############################################\n",
        "    # binary CD\n",
        "    ###############################################\n",
        "    print('-------Perform Binary Change Detection-------')\n",
        "    rou = np.reshape(rou, (-1, 1))\n",
        "    binary_change_map = get_binary_change_map(rou, method='otsu')\n",
        "    binary_change_map = np.reshape(binary_change_map, (height, width))\n",
        "    binary_change_map_rgb = np.repeat(binary_change_map[:, :, np.newaxis], 3, axis=2)\n",
        "    imageio.imwrite(os.path.join(SAVE_PATH, 'KPCAMNet_BCM.png'), binary_change_map_rgb.astype(np.uint8))\n",
        "\n",
        "    ###############################################\n",
        "    # multi-class CD\n",
        "    ###############################################\n",
        "    print('-------Perform Multi-class Change Detection-------')\n",
        "    changed_idx = (binary_change_map == 255)\n",
        "    changed_theta = theta[changed_idx]\n",
        "    changed_theta = np.reshape(changed_theta, (-1, 1))\n",
        "    KMeans_cls = KMeans(n_clusters=3, max_iter=1500)\n",
        "    print('-------Clustering algorithm is running')\n",
        "    KMeans_cls.fit(changed_theta)\n",
        "    label_pred = KMeans_cls.labels_  # get cluster label\n",
        "\n",
        "    multi_change_map = np.zeros((height, width, 3))\n",
        "    k = 0\n",
        "    for h in range(height):\n",
        "        for w in range(width):\n",
        "            if changed_idx[h, w]:\n",
        "                if label_pred[k] == 0:\n",
        "                    multi_change_map[h, w] = np.array([255, 255, 0])\n",
        "                elif label_pred[k] == 1:\n",
        "                    multi_change_map[h, w] = np.array([255, 0, 0])\n",
        "                elif label_pred[k] == 2:\n",
        "                    multi_change_map[h, w] = np.array([0, 0, 255])\n",
        "                k += 1\n",
        "    multi_change_map_uint8 = (multi_change_map * 255).astype(np.uint8)\n",
        "    imageio.imwrite(os.path.join(SAVE_PATH, 'KPCAMNet_MCM.png'), multi_change_map_uint8)\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    args = {\n",
        "          'net_depth': 3,\n",
        "          'patch_size': 5,\n",
        "          # Add other arguments as needed\n",
        "      }\n",
        "    train_net(args)"
      ]
    }
  ]
}